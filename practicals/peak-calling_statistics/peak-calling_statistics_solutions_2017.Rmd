---
title: "Solutions - basic peak-calling statistics (2017)"
author: "Jacques van Helden"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
    collapsed: true
    code_folding: hide
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
  word_document: default
bibliography: peak-calling_statistics.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, comment = "", fig.width = 7, fig.height = 5)
```


# Introduction


The goal of this tutorial is to explore ChIP-seq data and to evaluate various statistics and graphical modes in order to detect peaks, i.e. regions with a significantly higher number of reads than what would be expected based on some background model. 

We will use a dataset from the bacteria *Escherichia coli K12*. Since bacteria have a relatively small genome compared to metazoans, the ChIP-seq dataset achieves a very high coverage, which gives us particularly interesting conditions to assess the validity of our prior assumptions.

********************
# Tasks

1. **Load** the ChIP-seq coverage profile and the genomic input. 

2. Plot the **coverage profiles**. 

3. Compute and represent graphically the **distributions of counts per bin**.

4. Compute and draw the **Lorenz curves** for the ChIP-seq data and for the genomic input^[Tip: you can use the R `cumsum()` function. ]. 

5. **Normalize** the counts per library (ChIP-seq, input) in order to compensate for the different sequencing depths. For this, you need to define a normalizing factor, which will multiply the counts in each sample. As normalizing factor, you can use the *libsum* (sum of read counts per sequencing library), but you might also think about more robust normalization factor, for example the median count, or the  $90^{th}$ percentile of the counts per bins.

6. Compute various scores that might be used to **compare the counts** per bin between ChIP-ped and input datasets. For each of the metrics, draw a plot to show the values of the comparison metrics. We might for example think about the following metrics:

    - $d = f_{i,C} - f_{i,G}$, the **difference** between normalized frequencies of the chip ($C$) and genomic input ($G$);
    - $r = \frac{f_{i,C}}{f_{i,G}}$, ChIP_seq / input ratio between normalized counts;
    - $log2FC = log_2(\frac{f_{i,C}}{f_{i,G}})$, the log-fold-change, i.e. the log2(ratio) between normalized frequencies;
    - $LLR = f_{i,G} \cdot ln(\frac{f_{i,C}}{f_{i,G}})$, i.e. background frequency multiplied by the log2(ratio);
    - ...
    
7. Based on the Poisson distribution, compute a **p-value** per bin, as well as an **adjusted p-value** (corrected for multiple testing). 

8. Draw a **volcano plot** with the log2-fold-change as measure of the effect size (abscissa) and the $-log_{10}(p_{adj})$ on the ordinate.

9. Select the **significant bins**.

10. **View the results in IGV** and compare the peaks identified with this rudimentary strategy with those returned by a real peak-caller. 

****************************************************************

# Data loading

We will first load the datasets.

We will load bedgraph-formatted files indicating the counts of reads per 200bp window along *E.coli* genome. 


```{r path to the course}
## Define the base URL of the course and store it in a variable
url.course <- "~/stats_avec_RStudio_EBA/"
#url.course <- "http://jvanheld.github.io/stats_avec_RStudio_EBA/"

## Define the fill path of the data directory, by concatenating the course URL and all the successive folders
url.data <- file.path(url.course, "practicals", "02_peak-calling", "data")

```


```{r loading the ChIP-seq counts}

## Define URL of the ChIP file
chip.bedg.file <- file.path(url.data, "FNR_200bp.bedg")
print(chip.bedg.file)

## Load the file content in an R data.frame
chip.bedg <- read.table(chip.bedg.file)

## Set column names
names(chip.bedg) <- c("chrom", "start", "end","counts")


## Check the dimensions of the bedgraph for the ChIP-seq
# dim(chip.bedg)
# summary(chip.bedg)

```

We loaded a tab-delimited file with the counts of reads per window in the FNR ChIP-seq sample. The table contains `r nrow(chip.bedg)` rows, each row corresponding to a genomic window. 


```{r loading the input counts}
## Define URL of the input file
input.bedg.file <- file.path(url.data, "input_200bp.bedg")

## Load the file content in an R data.frame
input.bedg <- read.table(input.bedg.file)

## Set column names
names(input.bedg) <- c("chrom", "start", "end","counts")

```


# Results

## Computation of the log2-counts


```{r log2_counts}
# Convert the data to log2-counts. 
# We first add an epsilon to avoid converting zero counts into -Inf values
epsilon <- 0.5 # We choose 0.5 because after log2 it gives -1
chip.bedg$log2counts <- log2(chip.bedg$counts + epsilon)
input.bedg$log2counts <- log2(input.bedg$counts + epsilon)
log2counts.min <- min(c(chip.bedg$log2counts, input.bedg$log2counts))
log2counts.max <- ceiling(max(c(chip.bedg$log2counts, input.bedg$log2counts)))
```


We apply a base-2 logarithmic transformation to the raw counts in order to perceive  count values over their full range without putting too much emphasis on the very high range, influenced by a handful of outlier values.

Before this, we add an arbitrary epsilon ($\epsilon=`r epsilon`$) to circumvent problems resulting from the transformation of zero counts to $-\infty$.

$$y = log_2(x_i + \epsilon)$$


## Plot the **coverage profiles**

## Distribution of read  counts per bin

```{r coverage_profiles, fig.width=10, fig.height=8, fig.cap="**Coverage profiles**."}

par(mfrow=c(4,1))
plot(x = chip.bedg$start/1000,
     y = chip.bedg$counts,
     main="ChIP-seq coverage",
     xlab="Bin start position (Kb)",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1,
     ylab="Read counts per bin")

plot(x = input.bedg$start/1000,
     y = input.bedg$counts,
     main="Genomic input coverage",
     xlab="Bin start position (Kb)",
     #     cex=0.5,
     col="grey",
     type="h",
     las=1,
     ylab="Read counts per bin")


plot(x = chip.bedg$start/1000,
     y = chip.bedg$log2counts,
     ylim=c(log2counts.min, log2counts.max),
     main="ChIP-seq coverage",
     xlab="Bin start position (Kb)",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1,
     ylab=paste("log2(counts per bin +", epsilon, ")"))

plot(x = input.bedg$start/1000,
     y = input.bedg$log2counts,
     ylim=c(log2counts.min, log2counts.max),
     main="Genomic input coverage",
     xlab="Bin start position (Kb)",
     #     cex=0.5,
     col="grey",
     type="h",
     las=1,
     ylab=paste("log2(counts per bin +", epsilon, ")"))

par(mfrow=c(1,1))

```

### Interpretation of the coverage profiles

- The coverage profile of the ChIP-ped sample shows striking peaks at different genomic positions. 

- The genomic input shows fluctuations, but no such peaks.

- Note that the scales are different: genomic input varies from `r min(input.bedg$counts)` to `r  max(input.bedg$counts)`, whereas the ChIP-seq peaks reach `r max(chip.bedg$counts)`.

- A strinking observation is that the coverage profile of the input is far from homogeneous: beyond the local fluctuations, at the scale of the whole chromosome, we observe a sinusoidal shape. This shape might be related to some biological property such as the directions of replication. In any case, whatever might be its case, we have to take it into account for the estimation of peak significance, since it means that the background model varies depending ont the chromosomal location. 



## Compute and represent graphically the **distributions of counts per bin**.


```{r count distribution, fig.width=10, fig.height=12, fig.cap="**Coverage profiles**."}

par(mfrow=c(4,1))

## A frist attempt, no very convincing
hist(chip.bedg$counts, breaks=1000, 
     xlab="Counts per bin", 
     ylab="Number of bins",
     main="ChIP-seq data")

# Reduce the X axis range
hist(chip.bedg$counts, breaks=2000, xlim=c(0, 800),
     xlab="Counts per bin (truncated axis)", 
     ylab="Number of bins",
     main="ChIP-seq data")

# Draw histogram of log2_converted counts
hist(chip.bedg$log2counts, breaks=200,
     xlim=c(log2counts.min, log2counts.max),
     xlab=paste("log2(counts +", epsilon, ")"),
     ylab="Number of bins",
     main="ChIP-seq log2-counts per bin",
     col="blue", border="darkblue")

hist(input.bedg$log2counts, breaks=200,
     xlim=c(log2counts.min, log2counts.max),
     xlab=paste("log2(counts +", epsilon, ")"),
     ylab="Number of bins",
     main="Genomic input log2-counts per bin",
     col="gray", border="darkgray")

par(mfrow=c(1,1))

```





## Compute and draw the **Lorenz curves** for the ChIP-seq data and for the genomic input^[Tip: you can use the R `cumsum()` function. ]. 

[@Diaz:2012ei]

```{r lorenz_curves, fig.width=5, fig.height=5, fig.cap="Lorenz curves."}
## We defined hereby a function that plots a Lorennz curve. 
## We document it with roxygen2, which willl enable us to incorporate it in an R package. 


#' @title Plot Lorenz curve and return normalised counts.
#' @author Jacques.van-Helden@univ-amu.fr
#' @description Plot a Lorenz curve to compare the cumulative distribution of counts between two coverage proviles (e.g. bedGraph or bigWig files), and compute the normalising factor corresponding to the most discriminating percentile of the cumulative distributiosn. 
#' @param chip.counts a vector of counts per bin for the immunoprecipitated sample
#' @param input.counts a vector of counts per bin for the control sample (e.g. genomic input). Must have the same length as chip.counts. 
#' @param plot.curves=TRUE Boolean value indicating whether the curves should be displayed or not.
#' @param return.stats=TRUE Boolean value indicating whether the normalisation statistics should be returned or not.
#' @return a list of statistics derived from Lorenz' curves.
#' @export
plot.lorenz <- function(chip.counts, 
                        input.counts,
                        plot.curves=TRUE,
                        return.stats=TRUE) {

  ## Compute number of bins
  nbins <- length(chip.counts)

  ## Instantiate a table of rank-based statistisc
  ## (one rwo per rank of the sorted counts)
  lorenz.table <- data.frame(
    rank=1:nbins,
    percentile=100*(1:nbins)/nbins,
    chip.cumsum = cumsum(sort(chip.counts)),
    input.cumsum = cumsum(sort(input.counts))
  )
  lorenz.table$chip.cdf <- lorenz.table$chip.cumsum / sum(chip.counts)
  lorenz.table$input.cdf <- lorenz.table$input.cumsum / sum(input.counts)
  lorenz.table$diff <- lorenz.table$input.cdf - lorenz.table$chip.cdf
  
  ## Identify the range where input and chip-seq differ most
  max.diff.rank <- lorenz.table$rank[which.max(lorenz.table$diff)]
  max.diff.percentile <- lorenz.table$percentile[which.max(lorenz.table$diff)]
  
  if (plot.curves) {
    plot(lorenz.table$percentile, lorenz.table$input.cdf*100, type="l", col="darkgrey",
         main="Lorenz curves", 
         xlab="Percentage of bins", 
         ylab="Percentage of reads",
         las=1,
         panel.first=grid())
    abline(v=c(0,100), col="black")
    abline(h=c(0,100), col="black")
    abline(a=0, b=1, lty="dashed")
    lines(lorenz.table$percentile, lorenz.table$chip.cdf*100, type="l", col="darkblue")

    abline(v=max.diff.percentile, col="pink")  
    arrows(x0=max.diff.percentile,  
           y0=lorenz.table$input.cdf[max.diff.rank]*100, 
           x1=max.diff.percentile, 
           y1=lorenz.table$chip.cdf[max.diff.rank]*100, angle = 20, length = 0.1, code=3, col="red", lwd=2)  
    
    legend("topleft", 
           legend=c(
             "ChIP-seq", 
             "input", 
             paste(sep="", "max difference = ", round(digits=3, max(lorenz.table$diff))*100, "%"),
             paste(sep="", "best percentile = ", round(digits=2, max.diff.percentile), "%")
           ), 
           col=c("darkblue", "darkgrey", "red", "pink"), lwd=2)
  }

  if (return.stats) {
    ## Normalize input counts according to the most discriminative percentile
    norm.factor <- lorenz.table[max.diff.rank, "chip.cumsum"] / lorenz.table[max.diff.rank, "input.cumsum"]
    
    result <- list(
      norm.factor = norm.factor,
      max.diff.percentile=max.diff.percentile,
      max.diff.rank=max.diff.rank,
      counts = data.frame(
        chip = chip.counts,
        input = input.counts,
        input.norm = input.counts*norm.factor),
      lorenz.table = lorenz.table
    )
    return(result)
  }
}

lorenz.result <- plot.lorenz(
  chip.counts = chip.bedg$counts, 
  input.counts = input.bedg$counts)

```

## **Normalize** the counts per library

.... (ChIP-seq, input) in order to compensate for the different sequencing depths. For this, you need to define a normalizing factor, which will multiply the counts in each sample. 


Several possibilities can be considered as normalizing factor.

1. The *libsum* ($\sum_{i=1}^{n}{x_i}$, sum of read counts per sequencing library) is conceptually simple but it is sensitive to the presence of outliers. In the case of ChIP-seq, outliers might result from the high ocncentrations of reads in the peaks, or from the presence of highly accessible regions that are over-sampled during the sequencing. 

2. The **median count** $\tilde{x}$ is a robust normalization factor. Other quantiles have sometimes been used in order to capture a larger fraction of the total reads, for example the third quartile, or the  $90^{th}$ percentile of the counts per bins.

3. A more specific treatment is to use as normalization factors the cumulative counts correspondig to the most discriminating percentile on Lorenz' curves [@Diaz:2012ei]. 


```{r normalisation}
# Median-based normalization
chip.summary = summary(chip.bedg$counts)
input.summary = summary(input.bedg$counts)

chip.summary["sum"] <- sum(chip.bedg$counts)
input.summary["sum"] <- sum(input.bedg$counts)

## Apply median-based normalisation on the input reads
input.bedg$counts.norm <- input.bedg$counts * chip.summary["Median"] / input.summary["Median"]
#median(input.bedg$counts.norm)

input.bedg$log2counts.norm <- log2(input.bedg$counts.norm + epsilon)

## Draw boxplots before / after normalization
par(mfrow=c(2,2))
boxplot(data.frame(
  chip=chip.bedg$counts, 
  input=input.bedg$counts),
  col=c("blue", "grey"))

boxplot(data.frame(
  chip=chip.bedg$log2counts, 
  input=input.bedg$log2counts),
  col=c("blue", "grey"))

boxplot(data.frame(
  chip=chip.bedg$counts, 
  input=input.bedg$counts.norm),
  col=c("blue", "grey"))

boxplot(data.frame(
  chip=chip.bedg$log2counts, 
  input=input.bedg$log2counts.norm),
  col=c("blue", "grey"))


par(mfrow=c(1,1))

```


```{r hist_with_ggplot, fig.width=8, fig.height=3}
## A solution to superpose the two histograms with ggplot()
## provided by Teresa Romero (2017-02-03)
library(ggplot2)

## Superposed histograms of the log2-counts
ggplot(chip.bedg,aes(x=log2counts)) +
  geom_histogram(aes(fill="ChIP-Seq"), alpha = 0.6, binwidth = 0.04) +
  geom_histogram(data=input.bedg, aes(fill="Genome input"), alpha = 0.6, binwidth = 0.04) +
  theme(panel.background = element_rect(fill = "white")) +
  theme(axis.line.x = element_line(color="black", size = 0.08),
        axis.line.y = element_line(color="black", size =0.08)) +
  scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) +
  labs(fill= " ") + labs(x="log2(counts per bin)") + labs(y="Number of bins") +
  ggtitle("Combined histogram of ChIP-Seq/Genome input") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```

```{r hist_with_ggplot_norm, fig.width=8, fig.height=3}
## Superposed histograms of the log2-counts
chip.bedg$log2counts.norm <- chip.bedg$log2counts
ggplot(chip.bedg,aes(x=log2counts.norm)) +
  geom_histogram(aes(fill="ChIP-Seq"), alpha = 0.6, binwidth = 0.04) +
  geom_histogram(data=input.bedg, aes(fill="Genome input"), alpha = 0.6, binwidth = 0.04) +
  theme(panel.background = element_rect(fill = "white")) +
  theme(axis.line.x = element_line(color="black", size = 0.08),
        axis.line.y = element_line(color="black", size =0.08)) +
  scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) +
  labs(fill= " ") + labs(x="log2(counts + 0.5)") + labs(y="Number of bins") +
  ggtitle("Combined histogram of ChIP-Seq/Genome input") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))

```



## Compute various scores that might be used to **compare the counts** per bin

... between ChIP-ped and input datasets. For each of the metrics, draw a plot to show the values of the comparison metrics. We might for example think about the following metrics:

- $d = f_{i,C} - f_{i,G}$, the **difference** between normalized frequencies of the chip ($C$) and genomic input ($G$);
- $r = \frac{f_{i,C}}{f_{i,G}}$, ChIP_seq / input ratio between normalized counts;
- $log2FC = log_2(\frac{f_{i,C}}{f_{i,G}})$, the log-fold-change, i.e. the log2(ratio) between normalized frequencies;
- $LLR = f_{i,G} \cdot ln(\frac{f_{i,C}}{f_{i,G}})$, i.e. background frequency multiplied by the log2(ratio);
- ...

```{r chip_vs_input_scores, fig.width=8, fig.height=10}
par(mfrow=c(4,1))

## Difference between chip and (normalised) input counts
chip.bedg$bg <- input.bedg$counts.norm
chip.bedg$diff <- chip.bedg$counts - chip.bedg$bg
plot(x = chip.bedg$start/1000,
     y = chip.bedg$diff,
     main="ChIP-seq - normalized input",
     xlab="Bin start position (Kb)",
     ylab="Count difference",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1)
abline(h=0)

## Ratio between chip and (normalised) input counts
chip.bedg$count.ratio <- (chip.bedg$counts + epsilon) / (chip.bedg$bg + epsilon)
plot(x = chip.bedg$start/1000,
     y = chip.bedg$count.ratio,
     main="ratio ChIP-seq / normalized input",
     xlab="Bin start position (Kb)",
     ylab="Count ratio",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1)
abline(h=1)

## Log-ratio between chip and (normalised) input counts
chip.bedg$log2.ratio <- log2(chip.bedg$count.ratio)
plot(x = chip.bedg$start/1000,
     y = chip.bedg$log2.ratio,
     main="Log2 fold-change",
     xlab="Bin start position (Kb)",
     ylab="log2(ratio)",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1)
abline(h=0)

## Log-ratio between chip and (normalised) input counts
chip.bedg$llr <- chip.bedg$bg * (chip.bedg$log2.ratio)
plot(x = chip.bedg$start/1000,
     y = chip.bedg$llr,
     main="Information",
     xlab="Bin start position (Kb)",
     ylab="LLR",
     #     cex=0.5,
     col="blue",
     type="h",
     las=1)
abline(h=0)

par(mfrow=c(1,1))
```

We compute the p-value following the Poisson distribution. This requires a single parameter: the expected number of occurrences per bin. The simplest way to estimate this parameter is to use, for each bin, the corresponding normalised counts. 

$$\hat{\lambda_i} = x'_{i,\text{input}}$$
However, the significance is very sensitive to fluctuations of the genomic input. 
MACS strategy to circumvent this problem is to smooth the background probabilities by estimating them on windows wider than the bins. This can be easily done by computin, for each bin, the average of the normalized input counts for the bin of interest and its $n$ neighbour windows on each side. 

$$\hat{\lambda_i} = \sum_{j=i-n}^{i+n}{x'_{j,\text{input}}}$$


```{r compute_pval}


```


## Compute a **p-value** per bin, as well as an **adjusted p-value**

$$P(X = x) = \frac{\lambda e^{-\lambda}}{k!}$$

```{r poisson_density, fig.width=10, fig.height=5, fig.cap="**Poisson density**, with $\\lambda = 3$. "}
x <- 0:20
#print(x)

p <- dpois(x, lambda=3)

plot(x, p, type="h", lwd=3,
     main="Poisson density",
     col="blue",
     xlab="X", ylab="P(X = x)")

x.obs <- 8

lines(x[x>= x.obs], p[x>=x.obs], type="h", lwd=3, col="red")


```




## Draw a **volcano plot** 

... with the log2-fold-change as measure of the effect size (abscissa) and the $-log_{10}(p_{adj})$ on the ordinate.

## Select the **significant bins**.

## View the results in IGV


... and compare the peaks identified with this rudimentary strategy with those returned by a real peak-caller. 


# References

